---
title: "Analysis"
author: "Ian Moore & Danny Foster"
date: "7/21/2020"
output:
  word_document: 
    toc: true
    toc_depth: 2
  html_document: default
---

```{r}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

```

# Setup

Load packages:
```{r}
library(here)
library(tidyverse)
library(sf)
library(ggplot2)
library(GGally)
library(glmmTMB)


source(here::here('00-R', 'model_validation.R'))
```

Load data:

```{r}
# log transform variables after adding the minimum non-zero value to each 
# observation (to avoid trying to take log(0))
log_transform = function(x){log(x+min(x[x>0]))}

# cover_long has 1 row per 0.25m segment, with columns for position (along 
# the 90m transect), species (specific cover), cover_type (broad cover categories), 
# and average height in cm 
cover_long = 
  readRDS(here::here('02-data', '02-for_analysis', 'cover_long.rds')) %>%
  
  # enforce level ordering for time, planting, and followup
  mutate(time = factor(time, levels = c('pre', 'post')),
         planting = factor(planting, levels = c('E', 'C')),
         followup = factor(followup, levels = c('N', 'H', 'G')) )

# patches has 1 row per contiguous patch of a cover_type. Patches can span 
# subtransects within a 90m transect, and we treat 0m as contiguous with 90m 
# (ie transects are treated as wrapping). Columns give the cover type, 
# average height, and along-transect length of each patch. fire_type is an 
# even coarser version of cover-type, with categories high low and none. 
patches = 
  readRDS(here::here('02-data', '02-for_analysis', 'patches.rds')) %>%
  
  # enforce level ordering for time
  mutate(time = factor(time, levels = c('pre', 'post')))

# observed data on shrub cover and fuel loads for the 10m sub-sub-transects. 
# note that the CWD load is an average at the 30m subtransect level, so we 
# expect strong correlation in fuel loads at the subtransect level. This 
# must be explicitly included in a model, either via a random effect for 
# subtransects or an explicitly spatial random effect. 
obs_10m = 
  readRDS(here::here('02-data', 
                     '02-for_analysis', 
                     'obs_10m.rds')) %>%
  
  # enforce level ordering for time
  mutate(time = factor(time, levels = c('pre', 'post'))) %>%
  
  # convert from .sf object to dataframe 
  mutate(x = st_coordinates(.)[,'X'],
         y = st_coordinates(.)[,'Y']) %>%
  as.data.frame() %>%
  dplyr::select(-geometry) %>%
  
  # make dummy variables for 'time'; this will allow different correlation 
  # structures for the different times
  mutate(pre = ifelse(time=='pre',TRUE,FALSE),
         post = ifelse(time=='post', TRUE, FALSE)) %>%
  
  # log transform the fuels
  mutate(log_total = log_transform(total_mgha),
         log_litterduff = log_transform(litterduff_mgha),
         log_fwd = log_transform(fwd_mgha),
         log_cwd = log_transform(cwd_mgha))




count_patches = 
  patches %>%
  group_by(time, treatment, planting, followup, 
           block, plot, transect) %>%
  summarise(n_patches = n()) %>%
  ungroup() %>%
  left_join(., 
            cover_long %>%
              group_by(time, transect) %>%
              summarise(transect_length = 0.25*n()) %>%
              ungroup())

# 1 row per cover type on each subtransect. columns giving observation IDs 
# and the percent of the subtransect occupied by each cover type
cover_agg = 
  cover_long %>%
  group_by(time, planting, followup,
           block, plot, transect, subtransect,
           cover_type) %>%
  summarise(cover_length = 0.25*n()) %>%
  ungroup() %>%
  complete(nesting(time, planting, followup, 
                  block, plot, transect, subtransect),
           cover_type) %>%
  mutate(cover_length = ifelse(is.na(cover_length), 0, cover_length)) %>%
  left_join(cover_long %>%
              group_by(time, planting, followup,
              block, plot, transect, subtransect) %>%
              summarise(subtransect_length = 0.25*n()) %>%
              ungroup()) %>%
  mutate(p_cover = cover_length / subtransect_length)


```

Print session info:

```{r}
sessionInfo()
```

# Data exploration

Data exploration plots. Used to check assumptions and inform analysis, not 
intended for publication.

## Fuel loads

### Y distributions

```{r}

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(time, planting, followup, fuel_component, load_mgha, x, y),
       aes(x = load_mgha))+
  geom_histogram()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(log_litterduff, log_fwd, log_cwd, log_total),
                      names_to = 'fuel_component',
                      values_to = 'log_mgha') %>%
         select(time, planting, followup, fuel_component, log_mgha, x, y),
       aes(x = log_mgha))+
  geom_histogram()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()

```

### X distributions

```{r}
ggplot(data = obs_10m,
       aes(x = time, fill = paste0(planting, ':', followup)))+
  geom_bar(position = position_stack())+
  theme_minimal()+
  scale_fill_viridis_d()

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(x, y),
                      names_to = 'axis',
                      values_to = 'coordinate'),
       aes(x = coordinate))+
  geom_histogram()+
  facet_wrap(~axis, scales = 'free')

ggplot(data = obs_10m,
       aes(x = x, y = y, color = block))+
  geom_point(size = 0)+
  theme_minimal()+
  coord_fixed()+
  scale_color_viridis_d(begin = 0.05, end = 0.85, option = 'C')

```

### XX relationships

```{r}
ggpairs(obs_10m %>% select(time, planting, followup, x, y))

```

### XY relationships and interactions




```{r}
ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = time))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = planting))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = followup))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = x))+
  geom_point(size = 0)+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(block, time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = block))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()


ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(block, time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = block, fill = time))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()+
  scale_fill_viridis_d(option = 'B', begin = 0.5, end = 0.75)

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(block, time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = planting, fill = time))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()+
  scale_fill_viridis_d(option = 'B', begin = 0.5, end = 0.75)

ggplot(data = 
         obs_10m %>%
         pivot_longer(c(litterduff_mgha, fwd_mgha, cwd_mgha, total_mgha),
                      names_to = c('fuel_component','units'),
                      values_to = 'load_mgha',
                      names_sep = '_') %>%
         select(block, time, planting, followup, fuel_component, load_mgha, x, y),
       aes(y = load_mgha, x = followup, fill = time))+
  geom_boxplot()+
  facet_wrap(~fuel_component, scales = 'free')+
  theme_minimal()+
  scale_fill_viridis_d(option = 'B', begin = 0.5, end = 0.75)


```

**Strongly** skewed fuel loads, even more so than is usual. Looks like time 
has an effect. Maybe 1 of the treatments too? Though the variation explained 
by treatment and block is similar. 1000h loads very strongly correlated with 
total loads, which makes sense given the fuel type (ots of down logs, not 
much FWD or litter / duff). Strong effect of time, but without clear interactions 
with planting and/or followup: Suggests that site-prep (which was applied 
universally) is most of the time effect. 

## Cover continuity

I think it makes more sense to describe cover continuity in terms of the 
number of patches per transect, rather than as the size of patches. Here's 
why:

```{r}
ggplot(data = patches,
       aes(x = time, fill = cover_type))+
  geom_bar()+
  theme_minimal()+
  scale_fill_viridis_d()+
  labs(y = 'Number of patches')

```

If we fit a model looking at the size of each patch, then the N for 
post-treatment (smaller patches) is way higher than for pre-treatment. 
I *think* LMEs can handle unbalanced data, but the LMEs I've run on 
patch size perform poorly on validation tests, even after log-transforming 
the sizes. 

Instead, we treat model the number of distinct patches on each transect:

### Y distributions

```{r}
ggplot(data = count_patches, 
       aes(x = n_patches/transect_length))+
  geom_histogram()+
  theme_minimal()

```

### X distributions and XX relationships

These are all categorical variables in the balanced study design:

```{r}
ggplot(data = count_patches,
       aes(x = time, fill = paste0(planting, ':', followup)))+
  geom_bar(position = position_stack())+
  theme_minimal()+
  scale_fill_viridis_d()+
  labs(y = 'N replicates (number of transects)')

```


### XY Relationships and interactions


```{r}
ggplot(data = count_patches,
       aes(x = n_patches/transect_length, color = time))+
  geom_density(lwd = 1)+
  scale_color_viridis_d(begin = 0.3, end = 0.6, option = 'B')+
  theme_minimal()
  
ggplot(data = count_patches,
       aes(x = n_patches/transect_length, color = planting))+
  geom_density(lwd = 1)+
  scale_color_viridis_d(begin = 0.3, end = 0.6, option = 'C')+
  theme_minimal()

ggplot(data = count_patches,
       aes(x = n_patches/transect_length, color = followup))+
  geom_density(lwd = 1)+
  scale_color_viridis_d(begin = 0.1, end = 0.8, option = 'D')+
  theme_minimal()

ggplot(data = count_patches,
       aes(x = n_patches/transect_length, color = time))+
  geom_density(lwd = 1)+
  scale_color_viridis_d(begin = 0.3, end = 0.6, option = 'B')+
  theme_minimal()+
  facet_grid(planting~followup)

```


## Cover composition

### Y distributions

```{r}

ggplot(data = cover_agg,
       aes(x = p_cover))+
  geom_histogram()+
  theme_minimal()

ggplot(data = cover_agg,
       aes(x = p_cover))+
  geom_density()+
  theme_minimal()

```

### X distributions and XX relationships

Again, all of the X variables are categorical variables and we have a balanced 
design. (Or mostly so; some subtransects are missing.)

### XY Relationships and interactions

```{r}
ggplot(data = cover_agg,
       aes(x = time, y = p_cover, fill = cover_type))+
  geom_col(position = position_fill())+
  theme_minimal()+
  scale_fill_viridis_d()

ggplot(data = cover_agg,
       aes(x = block, y = p_cover, fill = cover_type))+
  geom_col(position = position_fill())+
  theme_minimal()+
  scale_fill_viridis_d()

ggplot(data = cover_agg,
       aes(x = block, y = p_cover, fill = cover_type))+
  geom_col(position = position_fill())+
  theme_minimal()+
  scale_fill_viridis_d()+
  facet_grid(.~time)

ggplot(data = cover_agg,
       aes(x = time, y = p_cover, fill = cover_type))+
  geom_col(position = position_fill())+
  theme_minimal()+
  scale_fill_viridis_d()+
  facet_grid(planting~followup)
```

## Spatial structure

```{r}




```

# Analyses

## Fuel loads

Note the distributions 
with lots of 0s and highly skewed positive-continuous values:  Good candidates 
for a tweedie (compound poisson gamma) model. 


Fit LMEs on log-transformed data:

```{r}
litterduff.lme = 
  nlme::lme(data = obs_10m,
            log_litterduff ~ time * planting * followup,
            random =~ 1|block/plot/transect/subtransect/subsubtransect)

validate_model(X_i = obs_10m,
               y_i = obs_10m$log_litterduff,
               yhat_i = fitted(litterduff.lme),
               ep_i = residuals(litterduff.lme))


```

This looks worse at first glance than I think it actually is. Theres a clear 
bimodal distribution to the residuals, which is a real problem. There's 
also two clear groups of fitted values, which is not a real problem. The zero-
truncation at the low end is evident in the residuals, but the residuals 
do appear homoskedastic. Litter-duff was the most skewed of the fuel components. 

```{r}
fwd.lme = 
  nlme::lme(data = obs_10m,
            log_fwd ~ time * planting * followup,
            random =~ 1|block/plot/transect/subtransect/subsubtransect)

validate_model(X_i = obs_10m,
               y_i = obs_10m$log_fwd,
               yhat_i = fitted(fwd.lme),
               ep_i = residuals(fwd.lme))


```

So-so. Again zero-truncation is skewing the residual distribution, even 
for a log-transformed response.

```{r}
cwd.lme = 
  nlme::lme(data = obs_10m,
            log_cwd ~ time * planting * followup,
            random =~ 1|block/plot/transect/subtransect/subsubtransect)

validate_model(X_i = obs_10m,
               y_i = obs_10m$log_cwd,
               yhat_i = fitted(cwd.lme),
               ep_i = residuals(cwd.lme))

```

These look OK. 

```{r}

# try an lme on log-totals:
total.lme = 
  nlme::lme(data = obs_10m,
            log_total ~ time * planting * followup,
            random =~ 1|block/plot/transect/subtransect/subsubtransect)

validate_model(X_i = obs_10m,
               y_i = obs_10m$log_total,
               yhat_i = fitted(total.lme),
               ep_i = residuals(total.lme))

```


This looks OK, but not great. There is an obvious decrease in the residual variance 
as the fitted values increase. The residuals are slightly skewed but pretty good. 
I also ran these models as a glmm with a tweedie-distributed response. Those 
models had good-but-not-perfect validation plots, but are more 
difficult to interpret. The fixed effect parameter estimates were very 
similar between the LME and GLMM versions, which is good evidence that the 
LME findings are robust. 



## Cover continuity

We run a GLMM on the poisson-distributed response, the number of patches 
per transect. The more patches per transect, the more discontinuous the cover. 
I've aggregated patches which using the high/low/no fuels categories described 
in the paper. Using a generalized poisson model (
$\text{Var} = \mu \times \text{exp} ( \eta )$) because the standard poisson 
$\text{Var} = \mu$ was overdispersed. Using the transect length / 90 as an 
offset to account for cut-off transects. The response is the number of 
patches per transect. 

```{r}
n_patches.fit = 
  glmmTMB(data = count_patches,
          n_patches ~ time * planting * followup + 
            (1|block/plot/transect),
          disp =~ 1,
          family = genpois(link = 'log'),
          offset = count_patches$transect_length/90)

summary(n_patches.fit)

plot(DHARMa::simulateResiduals(n_patches.fit))
```

Validation plots look great!

Also doing an LME on log(patch size):

```{r}
patch_size.fit = 
  nlme::lme(data = 
              patches %>%
              mutate(log_size = log(cover_length)),
          log_size ~ time * planting * followup, 
          random =~ 1|block/plot/transect)

validate_model(X_i = patches,
               y_i = log(patches$cover_length),
               yhat_i = fitted(patch_size.fit),
               ep_i = residuals(patch_size.fit))


```

Validation plots look pretty good. 



## Cover composition

Fitting a multinomial model is hard, and a multinomial mixed model is harder. 
Instead just report summary statistics as in the current draft:

```{r}
composition_results = 
  cover_agg %>%
  group_by(time, cover_type) %>%
  summarise(p_cover.mean = mean(cover_length/subtransect_length),
            p_cover.sd = sd(cover_length/subtransect_length))



```

This could be turned into an actual statistical model if reviewers want us to.

## Spatial structure

### Select kappa

Following the recommendation of diggle & rubiero, we select a few values of 
kappa, use MLE to estimate the other parameters, and compare the log likelihoods 
for each of the few models to select the best values of kappa. 

```{r}
library(spaMM)

D = dist(obs_10m[,c('x', 'y')]) %>% as.matrix()



hif_kappa_05 = 
  fitme(data = obs_10m %>% filter(time == 'pre'),
        high_intensity_fuels ~ 1 + Matern(1|x+y),
        family = binomial(link = 'logit'),
        distMatrix = D,
        fixed = list(corrPars = list("1" = list('nu' = 0.5))),
        verbose = TRUE)

saveRDS(hif_kappa_05,
        here::here('02-data', '03-results', 'hif_kappa05.rds'))

hif_kappa_15 = 
  fitme(data = obs_10m,
        high_intensity_fuels ~ time + Matern(1|x+y)+Matern(pre|x+y) + Matern(post|x+y),
        family = binomial(link = 'logit'),
        distMatrix = D,
        fixed = list(corrPars = list('1' = list(nu = 1.5),
                                    '2' = list(nu = 1.5),
                                    '3' = list(nu = 1.5))),
        verbose = TRUE)

saveRDS(hif_kappa_05,
        here::here('02-data', '03-results', 'hif_kappa05.rds'))

hif_kappa_25 = 
  fitme(data = obs_10m,
        high_intensity_fuels ~ time + Matern(1|x+y)+Matern(pre|x+y) + Matern(post|x+y),
        family = binomial(link = 'logit'),
        distMatrix = D,
        fixed = list(corrPars = list('1' = list(nu = 2.5),
                                    '2' = list(nu = 2.5),
                                    '3' = list(nu = 2.5))),
        verbose = TRUE)

saveRDS(hif_kappa_05,
        here::here('02-data', '03-results', 'hif_kappa05.rds'))



```


### Profile log likelihood for nu1 and nu2

Define a grid of values for nu1 or nu2, use MLE to estimate the other 
parameters (holding either nu1/kappa1/kappa2 fixed or nu2/kappa1/kappa2 fixed),
store the log likelihoods for each of the models. Use chi2 test to 
construct confidence intervals. (Is there a better way than the grid? Try 
widening intervals around the MLE estimate of nu1 or nu2, do the chi2 test, 
and stop when you find the edge of the CI? Probably fewer iterations but 
harder to code, especially harder to code efficiently.) Grid version  
parallelizes easily. Does this all need to be 1 model, or separate models for 
pre and post? If its all 1 model, shouldn't I be allowing cross-correlation?)



### Fit 

```{r}
shrubs.fit = 
  fitme(data = obs_10m,
        high_intensity_fuels ~ time + Matern(1|x+y)+Matern(pre|x+y) + Matern(post|x+y),
        family = binomial(link = 'logit'),
        distMatrix = D,
        fixed = list(corrPars = list('1' = list(nu = 1.5),
                                    '2' = list(nu = 1.5)),
        verbose = TRUE))
summary(shrubs.fit)


matern = 
  function(kappa, phi){
    
    # eqation 3.6 in section 3.4.1 of model-based-geostatistics
    rho = 
      function(u){
        
        # if the distance is 0, the correlation between S_i and S_i' is 1
        ifelse(u == 0,
               1,
               
               # otherwise, the correlation is defined by the matern function
               # with parameters kappa and phi (equation 3.6 in section 3.4.1)
               (((2^(kappa-1))*gamma(kappa))^(-1)) * 
                 ((u / phi)^kappa) * 
                 # I'm not 100% that this is the correct modified bessel function, but
                 # the text uses the notation K_kappa() and everywhere I can find 
                 # the modified bessel function of the 3rd kind (aka modified bessel 
                 # function of the 2nd kind) is denoted using K rather than I, so I'm 
                 # assuming thats the one intended in the text. Other sources 
                 # explicitly mention modified bessel of the 2nd kind.
                 besselK(x = u / phi,
                         nu = kappa))
        
      }
    
    return(rho)
  }
gamma1_u = 
  
  function(u){
    shrubs.fit$lambda[1] * matern(kappa = shrubs.fit$corrPars$`1`$nu,
                  phi = 1/shrubs.fit$corrPars$`1`$rho)(u)
    }

gamma2_u = 
  
  function(u){
    shrubs.fit$lambda[2] * matern(kappa = shrubs.fit$corrPars$`2`$nu,
                  phi = 1/shrubs.fit$corrPars$`2`$rho)(u)
    }
corr_funs = 
  data.frame(u = seq(from = 0, to = 500, by = 10)) %>%
  mutate(pre = gamma1_u(u),
         post = gamma2_u(u)) %>%
  pivot_longer(c(pre, post), names_to = c('time'), values_to = 'cov_u')

head(corr_funs)

ggplot(data = corr_funs,
       aes(x = u, y = cov_u, color = time))+
  geom_point()+
  geom_line()


rho.1_grid = seq(from = 0.001, to = 0.2, by = 0.001)

rho.1_profile = 
  sapply(X = rho.1_grid,
         FUN = function(rho1_i){
           
           newfit = 
             shrubs.fit %>% 
             update(fixed = list(corrPars = list('1' = list(nu = 1.5, 
                                                            rho = rho1_i))))
           
           return(logLik(newfit))
           
         })

rho.2_grid = seq(from = 0.001, to = 0.5, by = 0.001)

rho.2_profile = 
  sapply(X = rho.2_grid,
         FUN = function(rho2_i){
           
           newfit = 
             shrubs.fit %>% 
             update(fixed = list(corrPars = list('2' = list(nu = 1.5, 
                                                            rho = rho2_i),
                                                '1' = shrubs.fit$corrPars$`1`),
                                  lambda = shrubs.fit$lambda),
              etaFix = list(beta = shrubs.fit$fixef))
           
           return(logLik(newfit))
           
         })

test = 
  data.frame(param = rep('rho_1', times = length(rho.1_grid)),
             value = rho.1_grid,
             loglik = rho.1_profile)

ggplot(data = test,
       aes(x = value, y = loglik, color = param))+
  geom_point()+
  geom_line()+
  geom_vline(xintercept = shrubs.fit$corrPars$`1`$rho, col = 'red', lty = 2)

summary(rho.1_profile)

summary(test)             
summary(shrubs.fit)

logLik(test)
logLik(shrubs.fit)

shrubs.fit$APHLs
test$APHLs


demo = expand.grid('x' = seq(from = 0, to = 500, by = 10),
                   'y' = seq(from = 0, to = 500, by = 10))

demo = 
  rbind(demo %>% mutate(time = 'pre', pre = 1, post = 0),
        demo %>% mutate(time = 'post', pre = 0, post = 1))

head(demo)

B = matrix(shrubs.fit$fixef, ncol = 1)
X_i = matrix(c(rep(1, times = nrow(demo)),
               demo$post),
             ncol = 2, byrow = FALSE)

XB = X_i %*% B

D = dist(demo[,c('x', 'y')]) %>% as.matrix()

generate_Sigma = 
  function(s_i, j_i, gamma_j, gamma_0){
    
    # n is the number of samples
    n = nrow(s_i)
    
    # get the pairwise distancce matrix D
    D = dist(s_i) %>% as.matrix()
    
    
    # if there is only 1 dimension of response
    if (is.null(j_i)){
      
      # then gamma_j should be length 1
      if(length(gamma_j)!=1){
        stop('No j_i matrix provided but multiple covariance functions given')
        }
      
      # just call the single covariance function on the distance matrix, 
      # which gives Sigma
      return(gamma_j(D))
      
    } else {
      
      # otherwise, get the number of dimensions, and continue on to construct 
      # the cross covariance matrix Sigma
      m = ncol(j_i)
      
    }
    
    # if there is a common component function (gamma_0)
    if (!is.null(gamma_0)){
      
      # n x n covariance matrix for the common component
      G_0 = gamma_0(D)
      
    } else {
      
      # common component contributes no covariance
      G_0 = matrix(data = 0, nrow = nrow(D), ncol = ncol(D))
      
    }
    
    
    # To start with, Sigma is equal to just the common component
    Sigma = G_0
    
    # loop over the columns in j_i, each representing a response dimension
    # each of the m columns column in j_i is a vector of 0s and 1s indicating whether the 
    # observation s_i is of response variable j (where j = 1,...,m)
    for (j in 1:m){
      
      # build an n x n indicator matrix for sample i, where each cell is 1 if 
      # both i and i' are of response type j, and 0 otherwise
      I_j = matrix(data = sapply(X = 1:n,
                                 FUN = function(i){j_i[i,j] * j_i[,j]}),
                   nrow = n,
                   ncol = n)
      
      # build the n x x covariance matrix for dimension j, assuming that 
      # every sample is of response dimension j, and so the cells are the covariance 
      # of sample j with itself at distance u. This will be multiplied by 0 
      # if i and i' are not both of response dimension j
      G_j = gamma_j[[j]](D)
      
      # add the covariance of j with itself to the cross covariance matrix sigma
      Sigma = Sigma + (I_j * G_j)
      
      
    }
    
    # return the cross-covariance matrix Sigma
    return(Sigma)
    
  }


Sigma = generate_Sigma(s_i = demo[,c('x', 'y')],
                       j_i = demo[,c('pre', 'post')],
                       gamma_j = 
                         c(function(u){
                           shrubs.fit$lambda[[1]]*matern(shrubs.fit$corrPars$`1`$nu,
                                                         1/shrubs.fit$corrPars$`1`$rho)(u)},
                           function(u){
                             shrubs.fit$lambda[[2]]*matern(shrubs.fit$corrPars$`2`$nu,
                                                         1/shrubs.fit$corrPars$`2`$rho)(u)}),
                       gamma_0 = NULL)

Z_i = Sigma %*% rnorm(n = nrow(demo), mean = 0, sd = 1)

mu_i = as.numeric(XB)+as.numeric(Z_i)

eta_i = exp(mu_i)/(exp(mu_i)+1)
summary(eta_i)
y_i = rbinom(n = nrow(demo), size = 1, prob = eta_i)

demo = 
  demo %>%
  mutate(XB = as.numeric(XB),
         Z_i = as.numeric(Z_i),
         mu_i = mu_i,
         eta_i = eta_i,
         y_i = as.factor(y_i))

ggplot(data = demo,
       aes(x = x, y = y, fill = y_i))+
  geom_tile()+
  coord_fixed()+
  scale_fill_viridis_d()+
  facet_wrap(~time)

ggplot(data = demo,
       aes(x = x, y = y, fill = mu_i))+
  geom_tile()+
  coord_fixed()+
  scale_fill_viridis_c()+
  facet_wrap(~time)

summary(shrubs.fit)
summary(demo[demo$time=='post','eta_i'])

ggplot(data = obs_30m,
       aes(x = sqrt(total_mgha)))+
  geom_histogram()+
  facet_wrap(~time)



# this is a little jank because not actually using the midpoints of each 
# 30m subtransect, instead using the 13m mark. Causing everything to be 
# shifted 2m west. Won't affect spatial relationship between observations, 
# could have minor effects (2m?) on spatial relationship between observations 
# and some correctly georeferenced covariate
obs_30m = 
  obs_10m %>%
  mutate(subsubtransect = gsub(subsubtransect, pattern = '^.*:', replacement = '')) %>%
  filter(subsubtransect == '13') %>%
  select(-subsubtransect)  %>%
  mutate(sqrt_total = sqrt(total_mgha))

head(obs_30m)

D30 = dist(obs_30m[,c('x', 'y')]) %>% as.matrix()

# also tried nu = 1.5 and nu = 2.5, both with worse LL
fuels.spaMM = 
  fitme(data = obs_30m,
        log_total ~ time + Matern(1|x+y)+Matern(pre|x+y)+Matern(post|x+y),
        family = gaussian(),
        fixed = list(corrPars = list('1' = list(nu = 0.5),
                                     '2' = list(nu = 0.5),
                                     '3' = list(nu = 0.5))),
        distMatrix = D30,
        verbose = TRUE)




summary(fuels.spaMM)
summary(fuels.spaMM2)
demo = expand.grid('x' = seq(from = 0, to = 1000, by = 30),
                   'y' = seq(from = 0, to = 1000, by = 30))

demo = 
  rbind(demo %>% mutate(time = 'pre', pre = 1, post = 0),
        demo %>% mutate(time = 'post', pre = 0, post = 1))

head(demo)


B = matrix(fuels.spaMM$fixef, ncol = 1)
X_i = matrix(c(rep(1, times = nrow(demo)),
               demo$post),
             ncol = 2, byrow = FALSE)

XB = X_i %*% B

D = dist(demo[,c('x', 'y')]) %>% as.matrix()

# function for back-transformed spatial covariance
gamma_T = 
  function(sigma, kappa, phi){
    
    function(u){
      
      exp(0+sigma^2)*(exp(sigma^2)-1)*
        (exp(sigma^2 * matern(kappa, phi)(u))-1)/
        (exp(sigma^2)-1)
      
    }
    
  }


Sigma_0 = 
  gamma_T(sigma = fuels.spaMM$lambda[[1]],
          kappa = fuels.spaMM$corrPars$`1`$nu,
          phi = 1/fuels.spaMM$corrPars$`1`$rho)(D)

Sigma_1 = 
  gamma_T(sigma = fuels.spaMM$lambda[[2]],
          kappa = fuels.spaMM$corrPars$`2`$nu,
          phi = 1/fuels.spaMM$corrPars$`2`$rho)(D)

Sigma_2 = 
  gamma_T(sigma = fuels.spaMM$lambda[[3]],
          kappa = fuels.spaMM$corrPars$`3`$nu,
          phi = 1/fuels.spaMM$corrPars$`3`$rho)(D)


Sigma = generate_Sigma(s_i = demo[,c('x', 'y')],
                       j_i = demo[,c('pre', 'post')],
                       gamma_j = 
                         c(gamma_T(sigma = fuels.spaMM$lambda[[2]],
                                   kappa = fuels.spaMM$corrPars$`2`$nu,
                                   phi = 1/fuels.spaMM$corrPars$`2`$rho),
                           gamma_T(sigma = fuels.spaMM$lambda[[3]],
                                   kappa = fuels.spaMM$corrPars$`3`$nu,
                                   phi = 1/fuels.spaMM$corrPars$`3`$rho)),
                       gamma_0 = gamma_T(sigma = fuels.spaMM$lambda[[1]],
                                   kappa = fuels.spaMM$corrPars$`1`$nu,
                                   phi = 1/fuels.spaMM$corrPars$`1`$rho))

sim_results = 
  do.call('rbind',
          lapply(X = 1:4,
                 FUN = function(sim){
                   
                     demo %>%
                      mutate(XB = 
                               as.numeric(XB),
                             T_i = 
                               as.numeric(Sigma %*% rnorm(n = nrow(demo), 
                                                          mean = (0), 
                                                          sd = 1)),
                             # i think this is probably not right
                             y_i = exp(XB)+T_i+exp(rnorm(n = nrow(demo),
                                                           mean = 0,
                                                           sd = sqrt(fuels.spaMM$phi))),
                             time = 
                               factor(time, levels = c('pre', 'post')),
                             sim_id = sim)
                   
                 }))


head(sim_results)

ggplot(data = sim_results,
       aes(x = x, y = y, fill = y_i))+
  geom_tile()+
  coord_fixed()+
  scale_fill_viridis_c()+
  facet_grid(sim_id~time)

  ggplot(data = sim_results,
       aes(x = x, y = y, fill = eta_i))+
  geom_tile()+
  coord_fixed()+
  scale_fill_viridis_c()+
  facet_grid(sim_id~time)

head(obs_30m)

```

# Results

## Fuel loads

Note that these parameters are for a linear model for the *log* fuel loads. 
Intercept group is pretreatment:cluster:grubbing. 

```{r}
round(summary(litterduff.lme)$tTable, 3)
round(summary(fwd.lme)$tTable, 3)
round(summary(cwd.lme)$tTable, 3)
round(summary(total.lme)$tTable, 3)

```



## Cover continuity

```{r}

summary(n_patches.fit)
```

## Cover composition

```{r}
composition_results
```

## Spatial structure of shrub patches

# Tables for publication

## Table 1: Changes in fuel loads

# Figures for publication

## Figures 1 and 2: Photos

## Figure 3: Sampling design

## Figure 4: Patch size distributions by cover type and time

## Figure 5: CDF functions for patch size distributions by time and intensity class

## Figure 6: Correlograms for shrub cover

# Write outputs

